{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import sys\n",
    "import json\n",
    "import numpy as np\n",
    "import time\n",
    "from PIL import Image, ImageDraw\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the ROOT_DIR variable to the root directory of the Mask_RCNN git repo\n",
    "ROOT_DIR = 'C:/Users/ISYSRG.COM/Documents/JO Gans/mask-rcnn covid/Mask_RCNN-master'\n",
    "assert os.path.exists(ROOT_DIR), 'ROOT_DIR does not exist. Did you forget to read the instructions above? ;)'\n",
    "\n",
    "# Import mrcnn libraries\n",
    "sys.path.append(ROOT_DIR) \n",
    "from mrcnn.config import Config\n",
    "import mrcnn.utils as utils\n",
    "from mrcnn import visualize\n",
    "import mrcnn.model as modellib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory to save logs and trained model\n",
    "MODEL_DIR = os.path.join(ROOT_DIR, \"logs\")\n",
    "\n",
    "# Local path to trained weights file\n",
    "COCO_MODEL_PATH = os.path.join(ROOT_DIR, \"mask_rcnn_coco.h5\")\n",
    "\n",
    "# Download COCO trained weights from Releases if needed\n",
    "if not os.path.exists(COCO_MODEL_PATH):\n",
    "    utils.download_trained_weights(COCO_MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CocoLikeDataset(utils.Dataset):\n",
    "    \"\"\" Generates a COCO-like dataset, i.e. an image dataset annotated in the style of the COCO dataset.\n",
    "        See http://cocodataset.org/#home for more information.\n",
    "    \"\"\"\n",
    "    def load_data(self, annotation_json, images_dir):\n",
    "        \"\"\" Load the coco-like dataset from json\n",
    "        Args:\n",
    "            annotation_json: The path to the coco annotations json file\n",
    "            images_dir: The directory holding the images referred to by the json file\n",
    "        \"\"\"\n",
    "        # Load json from file\n",
    "        json_file = open(annotation_json)\n",
    "        coco_json = json.load(json_file)\n",
    "        json_file.close()\n",
    "        \n",
    "        # Add the class names using the base method from utils.Dataset\n",
    "        source_name = \"coco_like\"\n",
    "        for category in coco_json['categories']:\n",
    "            class_id = category['id']\n",
    "            class_name = category['name']\n",
    "            if class_id < 1:\n",
    "                print('Error: Class id for \"{}\" cannot be less than one. (0 is reserved for the background)'.format(class_name))\n",
    "                return\n",
    "            \n",
    "            self.add_class(source_name, class_id, class_name)\n",
    "        \n",
    "        # Get all annotations\n",
    "        annotations = {}\n",
    "        for annotation in coco_json['annotations']:\n",
    "            image_id = annotation['image_id']\n",
    "            if image_id not in annotations:\n",
    "                annotations[image_id] = []\n",
    "            annotations[image_id].append(annotation)\n",
    "        \n",
    "        # Get all images and add them to the dataset\n",
    "        seen_images = {}\n",
    "        for image in coco_json['images']:\n",
    "            image_id = image['id']\n",
    "            if image_id in seen_images:\n",
    "                print(\"Warning: Skipping duplicate image id: {}\".format(image))\n",
    "            else:\n",
    "                seen_images[image_id] = image\n",
    "                try:\n",
    "                    image_file_name = image['file_name']\n",
    "                    image_width = image['width']\n",
    "                    image_height = image['height']\n",
    "                except KeyError as key:\n",
    "                    print(\"Warning: Skipping image (id: {}) with missing key: {}\".format(image_id, key))\n",
    "                \n",
    "                image_path = os.path.abspath(os.path.join(images_dir, image_file_name))\n",
    "                image_annotations = annotations[image_id]\n",
    "                \n",
    "                # Add the image using the base method from utils.Dataset\n",
    "                self.add_image(\n",
    "                    source=source_name,\n",
    "                    image_id=image_id,\n",
    "                    path=image_path,\n",
    "                    width=image_width,\n",
    "                    height=image_height,\n",
    "                    annotations=image_annotations\n",
    "                )\n",
    "                \n",
    "    def load_mask(self, image_id):\n",
    "        \"\"\" Load instance masks for the given image.\n",
    "        MaskRCNN expects masks in the form of a bitmap [height, width, instances].\n",
    "        Args:\n",
    "            image_id: The id of the image to load masks for\n",
    "        Returns:\n",
    "            masks: A bool array of shape [height, width, instance count] with\n",
    "                one mask per instance.\n",
    "            class_ids: a 1D array of class IDs of the instance masks.\n",
    "        \"\"\"\n",
    "        image_info = self.image_info[image_id]\n",
    "        annotations = image_info['annotations']\n",
    "        instance_masks = []\n",
    "        class_ids = []\n",
    "        \n",
    "        for annotation in annotations:\n",
    "            class_id = annotation['category_id']\n",
    "            mask = Image.new('1', (image_info['width'], image_info['height']))\n",
    "            mask_draw = ImageDraw.ImageDraw(mask, '1')\n",
    "            for segmentation in annotation['segmentation']:\n",
    "                mask_draw.polygon(segmentation, fill=1)\n",
    "                bool_array = np.array(mask) > 0\n",
    "                instance_masks.append(bool_array)\n",
    "                class_ids.append(class_id)\n",
    "\n",
    "        mask = np.dstack(instance_masks)\n",
    "        class_ids = np.array(class_ids, dtype=np.int32)\n",
    "        \n",
    "        return mask, class_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Configurations:\n",
      "BACKBONE                       resnet50\n",
      "BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n",
      "BATCH_SIZE                     1\n",
      "BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n",
      "COMPUTE_BACKBONE_SHAPE         None\n",
      "DETECTION_MAX_INSTANCES        100\n",
      "DETECTION_MIN_CONFIDENCE       0.7\n",
      "DETECTION_NMS_THRESHOLD        0.3\n",
      "FPN_CLASSIF_FC_LAYERS_SIZE     1024\n",
      "GPU_COUNT                      1\n",
      "GRADIENT_CLIP_NORM             5.0\n",
      "IMAGES_PER_GPU                 1\n",
      "IMAGE_CHANNEL_COUNT            3\n",
      "IMAGE_MAX_DIM                  512\n",
      "IMAGE_META_SIZE                15\n",
      "IMAGE_MIN_DIM                  512\n",
      "IMAGE_MIN_SCALE                0\n",
      "IMAGE_RESIZE_MODE              square\n",
      "IMAGE_SHAPE                    [512 512   3]\n",
      "LEARNING_MOMENTUM              0.9\n",
      "LEARNING_RATE                  0.001\n",
      "LOSS_WEIGHTS                   {'rpn_class_loss': 1.0, 'rpn_bbox_loss': 1.0, 'mrcnn_class_loss': 1.0, 'mrcnn_bbox_loss': 1.0, 'mrcnn_mask_loss': 1.0}\n",
      "MASK_POOL_SIZE                 14\n",
      "MASK_SHAPE                     [28, 28]\n",
      "MAX_GT_INSTANCES               50\n",
      "MEAN_PIXEL                     [123.7 116.8 103.9]\n",
      "MINI_MASK_SHAPE                (56, 56)\n",
      "NAME                           fetal\n",
      "NUM_CLASSES                    3\n",
      "POOL_SIZE                      7\n",
      "POST_NMS_ROIS_INFERENCE        500\n",
      "POST_NMS_ROIS_TRAINING         1000\n",
      "PRE_NMS_LIMIT                  6000\n",
      "ROI_POSITIVE_RATIO             0.33\n",
      "RPN_ANCHOR_RATIOS              [0.5, 1, 2]\n",
      "RPN_ANCHOR_SCALES              (8, 16, 32, 64, 128)\n",
      "RPN_ANCHOR_STRIDE              1\n",
      "RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n",
      "RPN_NMS_THRESHOLD              0.7\n",
      "RPN_TRAIN_ANCHORS_PER_IMAGE    256\n",
      "STEPS_PER_EPOCH                500\n",
      "TOP_DOWN_PYRAMID_SIZE          256\n",
      "TRAIN_BN                       False\n",
      "TRAIN_ROIS_PER_IMAGE           32\n",
      "USE_MINI_MASK                  True\n",
      "USE_RPN_ROIS                   True\n",
      "VALIDATION_STEPS               5\n",
      "WEIGHT_DECAY                   0.0001\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class fetalConfig(Config):\n",
    "    \"\"\"Configuration for training on the cigarette butts dataset.\n",
    "    Derives from the base Config class and overrides values specific\n",
    "    to the cigarette butts dataset.\n",
    "    \"\"\"\n",
    "    # Give the configuration a recognizable name\n",
    "    NAME = \"fetal\"\n",
    "\n",
    "    # Train on 1 GPU and 1 image per GPU. Batch size is 1 (GPUs * images/GPU).\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "\n",
    "    # Number of classes (including background)\n",
    "    NUM_CLASSES = 1 + 2  # background + 1 (cig_butt)\n",
    "\n",
    "    # All of our training images are 512x512\n",
    "    IMAGE_MIN_DIM = 512\n",
    "    IMAGE_MAX_DIM = 512\n",
    "\n",
    "    # You can experiment with this number to see if it improves training\n",
    "    STEPS_PER_EPOCH = 500\n",
    "\n",
    "    # This is how often validation is run. If you are using too much hard drive space\n",
    "    # on saved models (in the MODEL_DIR), try making this value larger.\n",
    "    VALIDATION_STEPS = 5\n",
    "    \n",
    "    # Matterport originally used resnet101, but I downsized to fit it on my graphics card\n",
    "    BACKBONE = 'resnet50'\n",
    "    \n",
    "    # To be honest, I haven't taken the time to figure out what these do\n",
    "    RPN_ANCHOR_SCALES = (8, 16, 32, 64, 128)\n",
    "    TRAIN_ROIS_PER_IMAGE = 32\n",
    "    MAX_GT_INSTANCES = 50 \n",
    "    POST_NMS_ROIS_INFERENCE = 500 \n",
    "    POST_NMS_ROIS_TRAINING = 1000 \n",
    "    \n",
    "config = fetalConfig()\n",
    "config.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InferenceConfig(fetalConfig):\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "    IMAGE_MIN_DIM = 512\n",
    "    IMAGE_MAX_DIM = 512\n",
    "    DETECTION_MIN_CONFIDENCE = 0.85\n",
    "    USE_MINI_MASK = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading weights from  C:/Users/ISYSRG.COM/Documents/JO Gans/mask-rcnn covid/Mask_RCNN-master/logs/resnet50_10-5/mask_rcnn_custom_0050.h5\n"
     ]
    }
   ],
   "source": [
    "inference_config = InferenceConfig()\n",
    "# Get path to saved weights\n",
    "# Either set a specific path or find last trained weights\n",
    "# model_path = os.path.join(ROOT_DIR, \".h5 file name here\")\n",
    "model_path = 'C:/Users/ISYSRG.COM/Documents/JO Gans/mask-rcnn covid/Mask_RCNN-master/logs/resnet50_10-5/mask_rcnn_custom_0050.h5'\n",
    "model = modellib.MaskRCNN(mode=\"inference\", \n",
    "                          config=inference_config,\n",
    "                          model_dir=MODEL_DIR)\n",
    "# Load trained weights (fill in path to trained weights here)\n",
    "assert model_path != \"\", \"Provide path to trained weights\"\n",
    "print(\"Loading weights from \", model_path)\n",
    "model.load_weights(model_path, by_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n"
     ]
    }
   ],
   "source": [
    "dataset_test = CocoLikeDataset()\n",
    "dataset_test.load_data('C:/Users/ISYSRG.COM/Documents/JO Gans/mask-rcnn covid/Mask_RCNN-master/dataset/custom/test.json', 'C:/Users/ISYSRG.COM/Documents/JO Gans/mask-rcnn covid/Mask_RCNN-master/dataset/custom/test')\n",
    "\n",
    "dataset_test.prepare()\n",
    "print(len(dataset_test.image_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "APs = []\n",
    "ious = []\n",
    "classes = [\"\",\"infected\",\"lungs\"]\n",
    "# np.random.shuffle(dataset_test.image_ids)\n",
    "T = {}\n",
    "P = {}\n",
    "all_class = []\n",
    "for image_id in dataset_test.image_ids:\n",
    "       \n",
    "   image, image_meta, gt_class_id, gt_bbox, gt_mask = modellib.load_image_gt(dataset_test, inference_config,\n",
    "                              image_id)\n",
    "   molded_images = np.expand_dims(modellib.mold_image(image, config), 0)\n",
    "   results = model.detect([image], verbose=0)\n",
    "   r = results[0]\n",
    "   \n",
    "\n",
    "   result = utils.compute_matches(gt_bbox, gt_class_id, gt_mask,\n",
    "                        r[\"rois\"], r[\"class_ids\"], r[\"scores\"], r['masks'])\n",
    "   \n",
    "   p_ids = r[\"class_ids\"]\n",
    "   g_ids = gt_class_id\n",
    "   all_class.append(g_ids)\n",
    "   gt = result[0]\n",
    "   pred = result[1]\n",
    "   scores = r[\"scores\"]\n",
    "   \n",
    "   t = {}\n",
    "   p = {}\n",
    "   \n",
    "   for i in range(len(pred)):\n",
    "       if pred[i] < 0:\n",
    "           cls_ids = p_ids[i]\n",
    "           if cls_ids not in p:\n",
    "               t[cls_ids] = []\n",
    "               p[cls_ids] = []\n",
    "           t[cls_ids].append(0)\n",
    "           p[cls_ids].append(scores[i])\n",
    "# =============================================================================\n",
    "#        else:\n",
    "#            cls_ids = g_ids[pred[i]]\n",
    "#            if cls_ids not in p:\n",
    "#                t[cls_ids] = []\n",
    "#                p[cls_ids] = []\n",
    "#            t[cls_ids].append(1)\n",
    "#            p[cls_ids].append(scores[i])\n",
    "# =============================================================================\n",
    "\n",
    "   for i in range(len(gt)):\n",
    "       if gt[i] < 0:\n",
    "           cls_ids = g_ids[i]\n",
    "           if cls_ids not in p:\n",
    "               t[cls_ids] = []\n",
    "               p[cls_ids] = []\n",
    "           t[cls_ids].append(1)\n",
    "           p[cls_ids].append(0)\n",
    "       else:\n",
    "           cls_ids = p_ids[int(gt[i])]\n",
    "           if cls_ids not in p:\n",
    "               t[cls_ids] = []\n",
    "               p[cls_ids] = []\n",
    "           t[cls_ids].append(1)\n",
    "           p[cls_ids].append(scores[int(gt[i])])\n",
    "           \n",
    "   for key in t.keys():\n",
    "        if key not in T:\n",
    "            T[key] = []\n",
    "            P[key] = []\n",
    "        T[key].extend(t[key])\n",
    "        P[key].extend(p[key])\n",
    "   ious.append((gt_class_id,result[-1], image_id))\n",
    "   \n",
    "   predicted_class_ids = r[\"class_ids\"]\n",
    "   \n",
    "   predicted_mask = r['masks']\n",
    "   for idx in range(len(predicted_class_ids)):\n",
    "      path_to_save = \"results/{}/\".format(classes[predicted_class_ids[idx]])\n",
    "      os.makedirs(path_to_save, exist_ok=True)\n",
    "      predicted = predicted_mask[:,:,idx]\n",
    "#       predicted = np.reshape(predicted, (512,512))  \n",
    "      img = Image.fromarray(predicted)\n",
    "      img.save(path_to_save+str(image_id)+\".jpg\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RESNET50 LR 10_3 GAN\n",
    "from sklearn.metrics import average_precision_score\n",
    "for key in T.keys():\n",
    "    ap = average_precision_score(T[key], P[key])\n",
    "    if np.isnan(ap):\n",
    "        ap = 0\n",
    "    print('{}\\t{}'.format(classes[key], ap))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
